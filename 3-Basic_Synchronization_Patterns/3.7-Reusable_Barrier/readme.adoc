# 3.7 Reusable Barrier

Oh, this section seems a mess to me.  The situation first presented is that
of a barrier inside a loop, but then the whole loop thing is never mentioned
again.

## chanSem.go

This is the literal implementation of section 3.7.5.

The text talks about a two-phase barrier, but haven't we been needing to do
this all along?  We needed in a number of programs so far to use a WaitGroup
to wait for all goroutines to complete before exiting main, in addition to
whatever other synchronization problem we were solving.

The solution code shows a line

`# rendezvous`

and a line

`# critical point`

But this is no more than was in the Barrier example.  What are we showing
that is new?  Apparently this trick of counting up and then counting down
which makes for two phases.  That doesn't seem to solve the loop problem
in general.

----
$ go run -race chanSem.go
2018/01/30 17:06:09 gr 1 rendezvous
2018/01/30 17:06:09 gr 4 rendezvous
2018/01/30 17:06:09 gr 3 rendezvous
2018/01/30 17:06:09 gr 2 rendezvous
2018/01/30 17:06:09 gr 5 rendezvous
2018/01/30 17:06:09 gr 1 critical point
2018/01/30 17:06:09 gr 4 critical point
2018/01/30 17:06:09 gr 3 critical point
2018/01/30 17:06:09 gr 2 critical point
2018/01/30 17:06:09 gr 5 critical point
----

## preloaded.go

This is the implemenation of section 3.7.6, Preloaded turnstile.  It uses
the SignalN addition to sem.ChanSem.

----
$ go run -race preloaded.go
2018/01/30 17:07:01 gr 1 rendezvous
2018/01/30 17:07:01 gr 5 rendezvous
2018/01/30 17:07:01 gr 2 rendezvous
2018/01/30 17:07:01 gr 3 rendezvous
2018/01/30 17:07:01 gr 4 rendezvous
2018/01/30 17:07:01 gr 4 critical point
2018/01/30 17:07:01 gr 3 critical point
2018/01/30 17:07:01 gr 2 critical point
2018/01/30 17:07:01 gr 1 critical point
2018/01/30 17:07:01 gr 5 critical point
----

## Reformulation

Let's reformulate this problem and try to do something more sensible.
I like the initially mentioned challenge of putting a barrier in a loop.
Let's do that, and simplify by having each worker output a message, then
reach the barrier.

## mainLoop.go

WaitGroups are reusable.  This was used in some previous examples.  The
example here is almost dead simple.  A worker just does some work -- printing
a message, and waits on the waitgroup.  Main runs a loop for any number of
cycles where it starts workers and waits for them to finish.  WaitGroups are
a kind of barrier.  They're pretty easy to reason about and use.

## barrier.go

In mainLoop.go, we dispensed with the channel close idiom even.  Can we revisit
the original barrier problem and simplify it in the same way?  Barrier.go is
it.  Just two kinds of work, each using the WaitGroup to signal completion.

It's starting to feel trivialized though.  What was the big deal in the last
chapter with the barrier in the worker goroutine?  The missing point is that
the barrier technique would be needed if the worker goroutines needed any kind
of continuity across the different kinds of work -- if they accumulated some
kind of per-worker result for example.  Unfortunately that was not given as a
requirement in the last section.  We jumped through some hoops without really
having a reason.

## Iterate on reformulation

Let's try again on making this problem really need a reusable barrier.  Say
there are multiple workers, that each must do some work then reach a barrier
then perhaps repeat, and that workers must independently accumulate some result
over their barrier-punctuated work cycles.

Now it's getting much more interesting.  Say main controls the number of cycles
and must communicate to the workers whether to do another cycle or to wrap up
their work.  The idea is to approach a technique that might be useful in
something like a physics simulation, where workers all compute something for
a new physical state staring from an existing physical state.

## data.go

Even with this more interesting problem, we still have a relatively simple
solution.  We are distributing some work across multiple goroutines and we
need data preserved across cycles.  We need a separate data workspace for each
running goroutine, but the simple solution is to create the workspaces outside
of the goroutines and simply pass a pointer to a workspace.  Goroutines are
cheap to create and are anonymous.

----
$ go run -race data.go
2018/02/04 14:27:43 cycle 0 gr 0 working
2018/02/04 14:27:43 cycle 0 gr 1 working
2018/02/04 14:27:43 cycle 0 gr 2 working
2018/02/04 14:27:43 cycle 1 gr 0 working
2018/02/04 14:27:43 cycle 1 gr 1 working
2018/02/04 14:27:43 cycle 1 gr 2 working
2018/02/04 14:27:43 cycle 2 gr 0 working
2018/02/04 14:27:43 cycle 2 gr 1 working
2018/02/04 14:27:43 cycle 2 gr 2 working
2018/02/04 14:27:43 cycle 3 gr 0 working
2018/02/04 14:27:43 cycle 3 gr 1 working
2018/02/04 14:27:43 cycle 3 gr 2 working
2018/02/04 14:27:43 count[0] = 4
2018/02/04 14:27:43 count[1] = 4
2018/02/04 14:27:43 count[2] = 4
----

## workerLoop.go

Finally, while the Go solutions described above are simple ways to solve
this type of problem, workerLoop.go is given as a Go solution more like the
two-phase barrier presented in the book.  It implements a two-phase barrier
within goroutines that are started once and run across all computation cycles
before terminating.  Workers must be ready to receive and act on two different
messages, a message to perform another cycle and a message to quit.  The Go
select statement handles this.

Main sends a cycleStart message to send the workers off on one more
computation cycle.  The additional cycleReset message is the second "phase".

Main sends a "quit" message if it needs no more computation cycles.  This
is the signal for the workers to wrap up and terminate.  We implement "wrap
up" as printing our accumulated count, this simple count being our result
accumulated over the work cycles.

The quit, cycleStart, and cycleReset messages are broadcast messages
implemented with the channel close technique introduced in section 3.6.

Then, this two-phase barrier between computation cycles is a little tricky.
Closing a channel is not a "reusable" operation.  That is, there is no way to
reopen a closed channel.  Channels are super cheap to create though.  No need
to reuse, just re-make the channel.  The trick is that to avoid a race
condition in recreating the cycleStart channel, we need this two-phase
technique.  We use one more channel, cycleReset, to make the second phase.
Each phase re-makes the channel for the other phase.

This two-phase solution is presented to show a solution much like the book
solution.  However, it is not recommend over the technique of `data.go`.
Comparing `data.go` and this solution, `workerLoop.go`, `data.go` is much
simpler and the low cost of goroutine creation keeps it fast.  The complexity
of `workerLoop.go` is not justified.

----
$ go run -race workerLoop.go
2018/02/04 14:27:10 cycle 0
2018/02/04 14:27:10   gr 0 working
2018/02/04 14:27:10   gr 2 working
2018/02/04 14:27:10   gr 1 working
2018/02/04 14:27:10 cycle 1
2018/02/04 14:27:10   gr 0 working
2018/02/04 14:27:10   gr 1 working
2018/02/04 14:27:10   gr 2 working
2018/02/04 14:27:10 cycle 2
2018/02/04 14:27:10   gr 2 working
2018/02/04 14:27:10   gr 1 working
2018/02/04 14:27:10   gr 0 working
2018/02/04 14:27:10 cycle 3
2018/02/04 14:27:10   gr 2 working
2018/02/04 14:27:10   gr 1 working
2018/02/04 14:27:10   gr 0 working
2018/02/04 14:27:10 gr 0 counted to 4
2018/02/04 14:27:10 gr 1 counted to 4
2018/02/04 14:27:10 gr 2 counted to 4
----
