# 3 Basic Synchronization Patterns
:toc:
:toc-placement: preamble

Chapter 3 introduces synchronization patterns used throughout the book.
In this repo, I present book solutions as given with these patterns, then
I go on to present solutions to the problem using more idiomatic Go patterns.

Below, in this readme, I document some of these Go patterns.  This is not a
comprehensive or perhaps even a balanced presentation of Go concurrency
patterns, rather it only covers patterns I have used in my solutions.

The patterns presented below are not organized into a particularly logical
order.  The order is roughly the order that the patterns are used in the Go
solutions in book chapter and section order.

(Non-Go patterns, as presented in the book, are covered in 3.x subdirectories,
the subdirectories under this one.)

## Goroutine

https://golang.org/ref/spec#Go_statements

Where the book says "thread" we read "goroutine".

One thing to remember is that main -- a main() function in a package main --
is running as a goroutine itself.  If another goroutine is started, then
there are two goroutines.

In `3.1-Signaling/chan.go` for example, only one goroutine is explicitly started
with a `go` statement; the other goroutine is simply main().

## Unbuffered channel

[no-bullet]
* https://golang.org/ref/spec#Channel_types
* https://golang.org/ref/spec#Send_statements
* https://golang.org/ref/spec#Receive_operator

An unbuffered channel is perhaps the simplest and most basic Go concurrency
element.

One goroutine sends a value, it then blocks until the other is ready to
receive.  Or, a goroutine ready to receive blocks until the other is ready
to send.  Either way, it represents a _synchronous rendezvous_.  One of the
two will wait until the other catches up and then one will be at it's send
statement at the same instant the the other is at its receive expression.

(Actually, of course, it's more complicated.  Read
https://golang.org/ref/mem[The Go Memory Model] if you must.)

The unbufferend channel is thus a synchronization element.  In addition though,
it is a _communication_ element.  A send sends a value to the other goroutine.
This value can be of any type and so can hold or reference arbitrarily
complex data.

### Synchronization

`3.1-Signaling/chan.go` uses a channel only for synchronizaton.  The channel
type is arbitrary and so is just something simple, an int, and the value
sent is a dummy value.  The receiving goroutine never even looks at the value.

### Communication

`3.4-Mutex/mutex.go` uses a mutex to protect a shared variable `count`.

A highly repeated quote from required reading
https://golang.org/doc/effective_go.html[Effective Go] is

____
https://golang.org/doc/effective_go.html#sharing[Do not communicate by sharing memory; instead, share memory by communicating.]
____

The version `3.4-Mutex\buffered.go` in contrast, uses a buffered channel to
replace both the mutex and the `count` variable, leaving no shared package
variable.  The channel send both synchronizes and communicates.
Using channels to both synchronize and communicate is highly recommended
to clarify and simplify concurrent code.

## WaitGroup

In the sync package of the Go standard library is the WaitGroup type.

https://golang.org/pkg/sync/#WaitGroup

It allows a goroutine to wait for multiple goroutines to finish doing
something.  First demonstrated in `3.3-Rendezvous/book.go` and `buffered.go`
programs, where main starts two goroutines and waits for them to finish.
Note this wait-to-finish operation is not described in section 3.3 of the
book.  The book does not describe how the thread code would be incorporated
into a complete program.  To make a complete simulation though, and use the
thread solutions from the book as literally as possible though, we need our
main() thread to start the A and B threads and then _wait for them to output
their results_ before terminating.

## Log package

https://golang.org/pkg/log/

An underdocumented and underappreciated feature of the log package is that it
does extra locking to ensure that functions such as log.Print() write their
output atomicly.  Output to stdout, for example is not generally guaranteed
by the operating system to be atomic.  Calls to fmt.Print() from separate
goroutines can actually generate interleaved output.

If `3.3-Rendezvous/book.go`, which writes output from two concurrent
goroutines, used fmt.Print, it can occasionally produce output like

----
statement a1
statement b1
statemstatement b1
ent a1
----

The use of log.Print guards against this.

## Mutex

https://golang.org/pkg/sync/#Mutex

`3.4-Mutex/mutex.go` introduced sync.Mutex.

## Buffered channel

(Language spec links are same as given above for unbuffered channels.)

There are a number of considerations for buffered channels that distinguish
them from unbuffered channels.

One is that if the buffer is not full, a send will write its value to the
channel without blocking.  It does not wait for a receiver.  This property is
used in `3.3-Rendezvous/buffered.go`, for example, to allow goroutines to run
in either order as they execute the line `IArrived <- 1`.  Either goroutine
can execute this line without waiting for the other goroutine.

Another consideration is that a program can follow conventions to use a
buffered channel as a way to accept, hold, and then release values.  The
program `3.4-Mutex/buffered.go` shows how a buffered channel (and some
convention) can implement mutually exclusive access to a value.

## Sync/atomic package

https://golang.org/pkg/sync/atomic/

Sync/atomic has a number of highly efficient functions for simple atomic
changes to single values.  `3.4-Mutex/atomic.go` uses atomic.AddInt64 for
example, for mutually exclusive access to a variable.

## Broadcast with close(), "quit" messages

https://golang.org/ref/spec#Close

Read the part about zero values.  A go idiom is to create a channel with a
dummy type and never send any values to it.  Multiple goroutines can attempt
to receive from the channel and all attempts will block _until the channel is
closed_.  At that point, all goroutines attempting to receive will immediately
succeed in receiving a zero value.  The effect is that a close() can broadcast
a signal to any number of goroutines.

`3.6-Barrier/close.go` uses this technique to implement the barrier described
in the section.

While this broadcast technique is generally useful, a very common Go idiom
is to use it to broadcast a "quit" message to goroutines as a signal that
they should terminate gracefully.

`3.7-Reusable-barrier/workerLoop.go` shows an example of this common idiom.
A select statement is inside of an infinite for loop.  One or more cases of
the select statement handle messages to do the main work of the goroutine,
then a case for the quit message causes the goroutine to terminate gracefully.

## Select

https://golang.org/ref/spec#Select_statements

Select is amazingly useful and powerful.  It allows a goroutine to handle
different messages without having to know which message will arrive next.

`3.7-Reusable-barrier/workerLoop.go` for example, shows this very common
pattern where one message means do some work and another message means quit.

## Time package

The Go standard library has very few places where the API uses a channel.
The time package has a few though.  See:

* https://golang.org/pkg/time/#After
* https://golang.org/pkg/time/#Tick
* https://golang.org/pkg/time/#Ticker
* https://golang.org/pkg/time/#Timer

These are useful in constructing some of the simulations of this repo.
`3.8-Queue/dance.go` for example uses time.After to simulate dancers arriving
at random intervals.

## All channels have unbounded queues

Commonly quoted is that unbounded queues or other data structures are trouble
because they allow memory or resources to be exhausted, often with catastrophic
or unforseen consequenses.  Go channels however, all maintain (internally)
queues of blocked goroutines, and these queues are unbounded.

`4.1-Producer-consumer/chan.go` for example uses these queues.  Nothing in the
program implements any queue directly.  The "queue" channel created is
unbuffered, with no inherent capacity to hold data values, yet the multiple
producer and consumer goroutines created will queue up as they block, waiting
for access.

Even `4.1-Producer-consumer/finite.go` uses these queues.  The queue channel is
created with capacity 3, yet 6 producers are started.  It is possible that 3
of the producers will complete channel sends while the other 3 queue up before
the consumers get around to receiving values.

In general, channel values will take much less memory than waiting goroutines.
If you have have lots of senders that might need to send before receivers are
available, it will usually be efficient to size a buffered channel to hold
roughly the number of sends you expect to be queued.

## Read-write mutex

https://golang.org/pkg/sync/#RWMutex

Used in `4.2-Readers-writers/rwmutex.go`

## Range over a channel

* https://golang.org/ref/spec#For_statements
* https://golang.org/ref/spec#For_range

Read down to the parts about channels.  This is a great compact syntax for
iterating over values received from a channel.  Iteration ends when the channel
is closed and all previously sent values have been received.  See use in
`4.5-Cigarette_smokers/table.go`.
